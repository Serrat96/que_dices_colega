{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eligible-purple",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dropout, Flatten, Dense, Activation\n",
    "from tensorflow.python.keras.layers import Convolution2D, MaxPooling2D\n",
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "from skimage.io import imread\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "diverse-garden",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "positive-philosophy",
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "hungarian-hudson",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_entrenamiento = './train'\n",
    "data_validacion = './test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "norman-wound",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parametros red neuronal\n",
    "\n",
    "epocas = 20\n",
    "altura, longitud = 100, 100\n",
    "batch_size = 32\n",
    "pasos = 200\n",
    "pasos_validacion = 20\n",
    "filtrosConv1 = 32\n",
    "filtrosConv2 = 64\n",
    "tamano_filtro1 = (3, 3)\n",
    "tamano_filtro2 = (2, 2)\n",
    "tamano_pool = (2, 2)\n",
    "clases = 29\n",
    "lr = 0.0005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "theoretical-strand",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filenames</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.jpg</td>\n",
       "      <td>G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.jpg</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.jpg</td>\n",
       "      <td>G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.jpg</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.jpg</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  filenames category\n",
       "0     0.jpg        G\n",
       "1     1.jpg        H\n",
       "2     2.jpg        G\n",
       "3     3.jpg        X\n",
       "4     4.jpg        H"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_df = pd.read_csv(r'.\\\\file_target.csv')\n",
    "\n",
    "images_df = images_df.rename(columns={'archivo': 'filenames',\n",
    "                       'target': 'category'})\n",
    "\n",
    "images_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "intelligent-extra",
   "metadata": {},
   "outputs": [],
   "source": [
    "entrenamiento, validacion = train_test_split(images_df, test_size = 0.19)\n",
    "\n",
    "entrenamiento = entrenamiento.reset_index(drop=True)\n",
    "\n",
    "validacion = validacion.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "endangered-procedure",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7290 validated image filenames belonging to 29 classes.\n",
      "Found 1710 validated image filenames belonging to 29 classes.\n"
     ]
    }
   ],
   "source": [
    "#Pre-procesamiento de las im√°genes\n",
    "#Primero creamos un generador que dice como vamos a preprocesar la info\n",
    "\n",
    "entrenamiento_datagen = ImageDataGenerator(rescale = 1.0/255.0,\n",
    "                                          shear_range = 0.3,\n",
    "                                          zoom_range = 0.3,\n",
    "                                          horizontal_flip = True)\n",
    "\n",
    "validacion_datagen = ImageDataGenerator(rescale = 1.0/255.0)\n",
    "\n",
    "imagen_entrenamiento = entrenamiento_datagen.flow_from_dataframe(entrenamiento,\n",
    "                                                                 data_entrenamiento,\n",
    "                                                                 target_size=(altura, longitud),\n",
    "                                                                 x_col='filenames',\n",
    "                                                                y_col='category',\n",
    "                                                                batch_size=batch_size,\n",
    "                                                                class_mode='categorical')\n",
    "\n",
    "imagen_validacion = validacion_datagen.flow_from_dataframe(validacion,\n",
    "                                                           data_entrenamiento,\n",
    "                                                          target_size=(altura, longitud),\n",
    "                                                           x_col='filenames',\n",
    "                                                            y_col='category',\n",
    "                                                          batch_size=batch_size,\n",
    "                                                          class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "stuck-lewis",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn=Sequential()\n",
    "\n",
    "cnn.add(Convolution2D(filtrosConv1, tamano_filtro1, padding='same', input_shape=(altura, longitud, 3), activation='relu'))\n",
    "\n",
    "cnn.add(MaxPooling2D(pool_size=tamano_pool))\n",
    "\n",
    "cnn.add(Convolution2D(filtrosConv2, tamano_filtro2, padding='same', activation='relu'))\n",
    "\n",
    "cnn.add(MaxPooling2D(pool_size=tamano_pool))\n",
    "\n",
    "cnn.add(Flatten())\n",
    "\n",
    "cnn.add(Dense(256, activation='relu'))\n",
    "\n",
    "cnn.add(Dropout(0.5))\n",
    "\n",
    "cnn.add(Dense(clases, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "legislative-material",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(loss='categorical_crossentropy', optimizer=optimizers.Adam(lr=lr), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "silent-effort",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "200/200 [==============================] - 29s 142ms/step - loss: 3.4216 - accuracy: 0.0393 - val_loss: 3.2863 - val_accuracy: 0.0672\n",
      "Epoch 2/20\n",
      "200/200 [==============================] - 29s 144ms/step - loss: 3.2733 - accuracy: 0.0709 - val_loss: 2.9886 - val_accuracy: 0.1531\n",
      "Epoch 3/20\n",
      "200/200 [==============================] - 29s 146ms/step - loss: 3.0555 - accuracy: 0.1179 - val_loss: 2.6608 - val_accuracy: 0.2359\n",
      "Epoch 4/20\n",
      "200/200 [==============================] - 27s 135ms/step - loss: 2.8582 - accuracy: 0.1713 - val_loss: 2.4095 - val_accuracy: 0.3078\n",
      "Epoch 5/20\n",
      "200/200 [==============================] - 27s 134ms/step - loss: 2.6598 - accuracy: 0.1915 - val_loss: 2.1511 - val_accuracy: 0.3375\n",
      "Epoch 6/20\n",
      "200/200 [==============================] - 27s 133ms/step - loss: 2.5113 - accuracy: 0.2387 - val_loss: 2.1066 - val_accuracy: 0.3531\n",
      "Epoch 7/20\n",
      "200/200 [==============================] - 27s 134ms/step - loss: 2.4189 - accuracy: 0.2601 - val_loss: 1.9459 - val_accuracy: 0.4313\n",
      "Epoch 8/20\n",
      "200/200 [==============================] - 27s 133ms/step - loss: 2.3257 - accuracy: 0.2633 - val_loss: 1.8674 - val_accuracy: 0.4500\n",
      "Epoch 9/20\n",
      "200/200 [==============================] - 27s 133ms/step - loss: 2.2047 - accuracy: 0.3091 - val_loss: 1.7645 - val_accuracy: 0.4344\n",
      "Epoch 10/20\n",
      "200/200 [==============================] - 27s 134ms/step - loss: 2.1371 - accuracy: 0.3275 - val_loss: 1.7080 - val_accuracy: 0.5016\n",
      "Epoch 11/20\n",
      "200/200 [==============================] - 27s 134ms/step - loss: 2.1110 - accuracy: 0.3327 - val_loss: 1.5809 - val_accuracy: 0.5406\n",
      "Epoch 12/20\n",
      "200/200 [==============================] - 30s 152ms/step - loss: 2.0219 - accuracy: 0.3563 - val_loss: 1.4866 - val_accuracy: 0.5594\n",
      "Epoch 13/20\n",
      "200/200 [==============================] - 30s 149ms/step - loss: 1.9321 - accuracy: 0.3703 - val_loss: 1.4313 - val_accuracy: 0.5656\n",
      "Epoch 14/20\n",
      "200/200 [==============================] - 28s 142ms/step - loss: 1.9098 - accuracy: 0.3794 - val_loss: 1.4461 - val_accuracy: 0.5266\n",
      "Epoch 15/20\n",
      "200/200 [==============================] - 31s 157ms/step - loss: 1.8740 - accuracy: 0.3915 - val_loss: 1.4048 - val_accuracy: 0.5875\n",
      "Epoch 16/20\n",
      "200/200 [==============================] - 29s 143ms/step - loss: 1.8578 - accuracy: 0.3826 - val_loss: 1.3529 - val_accuracy: 0.5672\n",
      "Epoch 17/20\n",
      "200/200 [==============================] - 29s 144ms/step - loss: 1.7867 - accuracy: 0.3984 - val_loss: 1.4027 - val_accuracy: 0.5469\n",
      "Epoch 18/20\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 1.7428 - accuracy: 0.4277 - val_loss: 1.2541 - val_accuracy: 0.6187\n",
      "Epoch 19/20\n",
      "200/200 [==============================] - 30s 149ms/step - loss: 1.6948 - accuracy: 0.4388 - val_loss: 1.2628 - val_accuracy: 0.5828\n",
      "Epoch 20/20\n",
      "200/200 [==============================] - 30s 149ms/step - loss: 1.7136 - accuracy: 0.4308 - val_loss: 1.1974 - val_accuracy: 0.6094\n"
     ]
    }
   ],
   "source": [
    "cnn.fit(imagen_entrenamiento, steps_per_epoch=pasos, epochs=epocas, validation_data=imagen_validacion, validation_steps=pasos_validacion)\n",
    "\n",
    "dir = './modelo/'\n",
    "\n",
    "if not os.path.exists(dir):\n",
    "    os.mkdir(dir)\n",
    "cnn.save('./modelo/modelo.h5')\n",
    "cnn.save_weights('./modelo/pesos.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
