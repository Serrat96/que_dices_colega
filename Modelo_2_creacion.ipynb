{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "conventional-september",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from keras.models import load_model\n",
    "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dropout, Flatten, Dense, Activation\n",
    "from tensorflow.python.keras.layers import Convolution2D, MaxPooling2D\n",
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "from skimage.io import imread\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "advised-democrat",
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "smart-birthday",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_entrenamiento = './train'\n",
    "data_validacion = './test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "stable-apparatus",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parametros red neuronal\n",
    "\n",
    "epocas = 20\n",
    "altura, longitud = 100, 100\n",
    "batch_size = 30\n",
    "pasos = 210\n",
    "pasos_validacion = 50\n",
    "filtrosConv1 = 60\n",
    "filtrosConv2 = 100\n",
    "tamano_filtro1 = (3, 3)\n",
    "tamano_filtro2 = (2, 2)\n",
    "tamano_pool = (2, 2)\n",
    "clases = 29\n",
    "lr = 0.0005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ambient-daisy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['G', 'H', 'X', 'Q', 'F', 'B', 'V', 'U', 'D', 'Y', 'L', 'space',\n",
       "       'Z', 'A', 'M', 'I', 'C', 'P', 'J', 'nothing', 'O', 'E', 'S', 'R',\n",
       "       'del', 'T', 'K', 'W', 'N'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_df = pd.read_csv(r'.\\\\file_target.csv')\n",
    "\n",
    "images_df = images_df.rename(columns={'archivo': 'filenames',\n",
    "                       'target': 'category'})\n",
    "\n",
    "#images_df = images_df.sort_values('category')\n",
    "\n",
    "images_df['category'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "crucial-curve",
   "metadata": {},
   "outputs": [],
   "source": [
    "entrenamiento, validacion = train_test_split(images_df, test_size = 0.19)\n",
    "\n",
    "entrenamiento = entrenamiento.reset_index(drop=True)\n",
    "\n",
    "#entrenamiento = entrenamiento.sort_values('category')\n",
    "\n",
    "validacion = validacion.reset_index(drop=True)\n",
    "\n",
    "#validacion = validacion.sort_values('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "mature-communication",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filenames</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3646.jpg</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1869.jpg</td>\n",
       "      <td>G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3650.jpg</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8826.jpg</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1376.jpg</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7285</th>\n",
       "      <td>632.jpg</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7286</th>\n",
       "      <td>1998.jpg</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7287</th>\n",
       "      <td>459.jpg</td>\n",
       "      <td>space</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7288</th>\n",
       "      <td>8802.jpg</td>\n",
       "      <td>K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7289</th>\n",
       "      <td>6791.jpg</td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7290 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     filenames category\n",
       "0     3646.jpg        A\n",
       "1     1869.jpg        G\n",
       "2     3650.jpg        Y\n",
       "3     8826.jpg        R\n",
       "4     1376.jpg        A\n",
       "...        ...      ...\n",
       "7285   632.jpg        W\n",
       "7286  1998.jpg        I\n",
       "7287   459.jpg    space\n",
       "7288  8802.jpg        K\n",
       "7289  6791.jpg        Z\n",
       "\n",
       "[7290 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "perfect-strap",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7290 validated image filenames belonging to 29 classes.\n",
      "Found 1710 validated image filenames belonging to 29 classes.\n"
     ]
    }
   ],
   "source": [
    "#Pre-procesamiento de las imágenes\n",
    "#Primero creamos un generador que dice como vamos a preprocesar la info\n",
    "\n",
    "entrenamiento_datagen = ImageDataGenerator(rescale = 1.0/255.0,\n",
    "                                          shear_range = 0.3,\n",
    "                                          zoom_range = 0.3,\n",
    "                                          horizontal_flip = True)\n",
    "\n",
    "validacion_datagen = ImageDataGenerator(rescale = 1.0/255.0)\n",
    "\n",
    "imagen_entrenamiento = entrenamiento_datagen.flow_from_dataframe(entrenamiento,\n",
    "                                                                 data_entrenamiento,\n",
    "                                                                 target_size=(altura, longitud),\n",
    "                                                                 x_col='filenames',\n",
    "                                                                y_col='category',\n",
    "                                                                batch_size=batch_size,\n",
    "                                                                class_mode='categorical')\n",
    "\n",
    "imagen_validacion = validacion_datagen.flow_from_dataframe(validacion,\n",
    "                                                           data_entrenamiento,\n",
    "                                                          target_size=(altura, longitud),\n",
    "                                                           x_col='filenames',\n",
    "                                                            y_col='category',\n",
    "                                                          batch_size=batch_size,\n",
    "                                                          class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "selected-induction",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn=Sequential()\n",
    "\n",
    "cnn.add(Convolution2D(filtrosConv1, tamano_filtro1, padding='same', input_shape=(altura, longitud, 3), activation='relu'))\n",
    "\n",
    "cnn.add(MaxPooling2D(pool_size=tamano_pool))\n",
    "\n",
    "cnn.add(Convolution2D(filtrosConv2, tamano_filtro2, padding='same', activation='relu'))\n",
    "\n",
    "cnn.add(MaxPooling2D(pool_size=tamano_pool))\n",
    "\n",
    "cnn.add(Flatten())\n",
    "\n",
    "cnn.add(Dense(256, activation='relu'))\n",
    "\n",
    "cnn.add(Dropout(0.5))\n",
    "\n",
    "cnn.add(Dense(clases, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "serial-excerpt",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(loss='categorical_crossentropy', optimizer=optimizers.Adam(lr=lr), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cultural-registration",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "210/210 [==============================] - 27s 128ms/step - loss: 0.7253 - accuracy: 0.7324 - val_loss: 0.2022 - val_accuracy: 0.9420\n",
      "Epoch 2/20\n",
      "210/210 [==============================] - 28s 133ms/step - loss: 0.7315 - accuracy: 0.7343 - val_loss: 0.1947 - val_accuracy: 0.9453\n",
      "Epoch 3/20\n",
      "210/210 [==============================] - 28s 134ms/step - loss: 0.7156 - accuracy: 0.7419 - val_loss: 0.2225 - val_accuracy: 0.9393\n",
      "Epoch 4/20\n",
      "210/210 [==============================] - 28s 134ms/step - loss: 0.7028 - accuracy: 0.7475 - val_loss: 0.2088 - val_accuracy: 0.9413\n",
      "Epoch 5/20\n",
      "210/210 [==============================] - 28s 134ms/step - loss: 0.7383 - accuracy: 0.7359 - val_loss: 0.2073 - val_accuracy: 0.9487\n",
      "Epoch 6/20\n",
      "210/210 [==============================] - 28s 134ms/step - loss: 0.6937 - accuracy: 0.7495 - val_loss: 0.1995 - val_accuracy: 0.9447\n",
      "Epoch 7/20\n",
      "210/210 [==============================] - 30s 142ms/step - loss: 0.6632 - accuracy: 0.7573 - val_loss: 0.2082 - val_accuracy: 0.9453\n",
      "Epoch 8/20\n",
      "210/210 [==============================] - 29s 140ms/step - loss: 0.6774 - accuracy: 0.7560 - val_loss: 0.2090 - val_accuracy: 0.9407\n",
      "Epoch 9/20\n",
      "210/210 [==============================] - 28s 134ms/step - loss: 0.7128 - accuracy: 0.7405 - val_loss: 0.2010 - val_accuracy: 0.9433\n",
      "Epoch 10/20\n",
      "210/210 [==============================] - 28s 135ms/step - loss: 0.6954 - accuracy: 0.7476 - val_loss: 0.2076 - val_accuracy: 0.9467\n",
      "Epoch 11/20\n",
      "210/210 [==============================] - 28s 134ms/step - loss: 0.6784 - accuracy: 0.7524 - val_loss: 0.2178 - val_accuracy: 0.9413\n",
      "Epoch 12/20\n",
      "210/210 [==============================] - 28s 135ms/step - loss: 0.6490 - accuracy: 0.7633 - val_loss: 0.2229 - val_accuracy: 0.9293\n",
      "Epoch 13/20\n",
      "210/210 [==============================] - 28s 136ms/step - loss: 0.6592 - accuracy: 0.7565 - val_loss: 0.2112 - val_accuracy: 0.9300\n",
      "Epoch 14/20\n",
      "210/210 [==============================] - 29s 138ms/step - loss: 0.6688 - accuracy: 0.7524 - val_loss: 0.2375 - val_accuracy: 0.9193\n",
      "Epoch 15/20\n",
      "210/210 [==============================] - 28s 134ms/step - loss: 0.6801 - accuracy: 0.7549 - val_loss: 0.1905 - val_accuracy: 0.9540\n",
      "Epoch 16/20\n",
      "210/210 [==============================] - 28s 135ms/step - loss: 0.6692 - accuracy: 0.7565 - val_loss: 0.1860 - val_accuracy: 0.9553\n",
      "Epoch 17/20\n",
      "210/210 [==============================] - 28s 134ms/step - loss: 0.6618 - accuracy: 0.7627 - val_loss: 0.1753 - val_accuracy: 0.9580\n",
      "Epoch 18/20\n",
      "210/210 [==============================] - 29s 137ms/step - loss: 0.6400 - accuracy: 0.7681 - val_loss: 0.1939 - val_accuracy: 0.9520\n",
      "Epoch 19/20\n",
      "210/210 [==============================] - 29s 137ms/step - loss: 0.6382 - accuracy: 0.7643 - val_loss: 0.1949 - val_accuracy: 0.9473\n",
      "Epoch 20/20\n",
      "210/210 [==============================] - 29s 140ms/step - loss: 0.6500 - accuracy: 0.7632 - val_loss: 0.1828 - val_accuracy: 0.9560\n"
     ]
    }
   ],
   "source": [
    "modelo='./modelo/modelo1.h5'\n",
    "\n",
    "cnn = load_model(modelo)\n",
    "\n",
    "cnn.fit(imagen_entrenamiento, steps_per_epoch=pasos, epochs=epocas, validation_data=imagen_validacion, validation_steps=pasos_validacion)\n",
    "\n",
    "dir = './modelo/'\n",
    "\n",
    "if not os.path.exists(dir):\n",
    "    os.mkdir(dir)\n",
    "cnn.save('./modelo/modelo1.h5')\n",
    "cnn.save_weights('./modelo/pesos1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "integrated-spice",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
