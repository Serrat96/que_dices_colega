{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "revolutionary-parliament",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from keras.models import load_model\n",
    "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dropout, Flatten, Dense, Activation\n",
    "from tensorflow.python.keras.layers import Convolution2D, MaxPooling2D\n",
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "from skimage.io import imread\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "administrative-influence",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "focused-mumbai",
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "handmade-tracker",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_entrenamiento = './train'\n",
    "data_validacion = './test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "utility-joshua",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parametros red neuronal\n",
    "\n",
    "epocas = 20\n",
    "altura, longitud = 100, 100\n",
    "batch_size = 32\n",
    "pasos = 200\n",
    "pasos_validacion = 50\n",
    "filtrosConv1 = 32\n",
    "filtrosConv2 = 64\n",
    "tamano_filtro1 = (3, 3)\n",
    "tamano_filtro2 = (2, 2)\n",
    "tamano_pool = (2, 2)\n",
    "clases = 29\n",
    "lr = 0.0005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "editorial-effects",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M',\n",
       "       'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z',\n",
       "       'del', 'nothing', 'space'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_df = pd.read_csv(r'.\\\\file_target.csv')\n",
    "\n",
    "images_df = images_df.rename(columns={'archivo': 'filenames',\n",
    "                       'target': 'category'})\n",
    "\n",
    "images_df = images_df.sort_values('category')\n",
    "\n",
    "images_df['category'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "technical-conflict",
   "metadata": {},
   "outputs": [],
   "source": [
    "entrenamiento, validacion = train_test_split(images_df, test_size = 0.19)\n",
    "\n",
    "entrenamiento = entrenamiento.reset_index(drop=True)\n",
    "\n",
    "entrenamiento = entrenamiento.sort_values('category')\n",
    "\n",
    "validacion = validacion.reset_index(drop=True)\n",
    "\n",
    "validacion = validacion.sort_values('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "magnetic-journey",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7290 validated image filenames belonging to 29 classes.\n",
      "Found 1710 validated image filenames belonging to 29 classes.\n"
     ]
    }
   ],
   "source": [
    "#Pre-procesamiento de las im√°genes\n",
    "#Primero creamos un generador que dice como vamos a preprocesar la info\n",
    "\n",
    "entrenamiento_datagen = ImageDataGenerator(rescale = 1.0/255.0,\n",
    "                                          shear_range = 0.3,\n",
    "                                          zoom_range = 0.3,\n",
    "                                          horizontal_flip = True)\n",
    "\n",
    "validacion_datagen = ImageDataGenerator(rescale = 1.0/255.0)\n",
    "\n",
    "imagen_entrenamiento = entrenamiento_datagen.flow_from_dataframe(entrenamiento,\n",
    "                                                                 data_entrenamiento,\n",
    "                                                                 target_size=(altura, longitud),\n",
    "                                                                 x_col='filenames',\n",
    "                                                                y_col='category',\n",
    "                                                                batch_size=batch_size,\n",
    "                                                                class_mode='categorical')\n",
    "\n",
    "imagen_validacion = validacion_datagen.flow_from_dataframe(validacion,\n",
    "                                                           data_entrenamiento,\n",
    "                                                          target_size=(altura, longitud),\n",
    "                                                           x_col='filenames',\n",
    "                                                            y_col='category',\n",
    "                                                          batch_size=batch_size,\n",
    "                                                          class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fifteen-container",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn=Sequential()\n",
    "\n",
    "cnn.add(Convolution2D(filtrosConv1, tamano_filtro1, padding='same', input_shape=(altura, longitud, 3), activation='relu'))\n",
    "\n",
    "cnn.add(MaxPooling2D(pool_size=tamano_pool))\n",
    "\n",
    "cnn.add(Convolution2D(filtrosConv2, tamano_filtro2, padding='same', activation='relu'))\n",
    "\n",
    "cnn.add(MaxPooling2D(pool_size=tamano_pool))\n",
    "\n",
    "cnn.add(Flatten())\n",
    "\n",
    "cnn.add(Dense(256, activation='relu'))\n",
    "\n",
    "cnn.add(Dropout(0.5))\n",
    "\n",
    "cnn.add(Dense(clases, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "atlantic-baseball",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(loss='categorical_crossentropy', optimizer=optimizers.Adam(lr=lr), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "august-opening",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "200/200 [==============================] - 27s 133ms/step - loss: 1.6955 - accuracy: 0.4206 - val_loss: 1.0881 - val_accuracy: 0.6556\n",
      "Epoch 2/20\n",
      "200/200 [==============================] - 28s 141ms/step - loss: 1.6705 - accuracy: 0.4299 - val_loss: 1.0871 - val_accuracy: 0.6712\n",
      "Epoch 3/20\n",
      "200/200 [==============================] - 31s 154ms/step - loss: 1.6640 - accuracy: 0.4285 - val_loss: 1.0807 - val_accuracy: 0.6500\n",
      "Epoch 4/20\n",
      "200/200 [==============================] - 30s 150ms/step - loss: 1.6618 - accuracy: 0.4285 - val_loss: 1.0418 - val_accuracy: 0.6837\n",
      "Epoch 5/20\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 1.6466 - accuracy: 0.4392 - val_loss: 1.1705 - val_accuracy: 0.6075\n",
      "Epoch 6/20\n",
      "200/200 [==============================] - 29s 146ms/step - loss: 1.6333 - accuracy: 0.4409 - val_loss: 0.9776 - val_accuracy: 0.7138\n",
      "Epoch 7/20\n",
      "200/200 [==============================] - 29s 144ms/step - loss: 1.6277 - accuracy: 0.4464 - val_loss: 1.0722 - val_accuracy: 0.6756\n",
      "Epoch 8/20\n",
      "200/200 [==============================] - 29s 144ms/step - loss: 1.6089 - accuracy: 0.4421 - val_loss: 0.9946 - val_accuracy: 0.6950\n",
      "Epoch 9/20\n",
      "200/200 [==============================] - 30s 150ms/step - loss: 1.5968 - accuracy: 0.4525 - val_loss: 1.0326 - val_accuracy: 0.6963\n",
      "Epoch 10/20\n",
      "200/200 [==============================] - 30s 149ms/step - loss: 1.5744 - accuracy: 0.4551 - val_loss: 1.0188 - val_accuracy: 0.6787\n",
      "Epoch 11/20\n",
      "200/200 [==============================] - 29s 146ms/step - loss: 1.5576 - accuracy: 0.4661 - val_loss: 0.9399 - val_accuracy: 0.7094\n",
      "Epoch 12/20\n",
      "200/200 [==============================] - 31s 153ms/step - loss: 1.5270 - accuracy: 0.4693 - val_loss: 0.9508 - val_accuracy: 0.7006\n",
      "Epoch 13/20\n",
      "200/200 [==============================] - 31s 153ms/step - loss: 1.5270 - accuracy: 0.4673 - val_loss: 0.9199 - val_accuracy: 0.7131\n",
      "Epoch 14/20\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 1.5286 - accuracy: 0.4673 - val_loss: 0.9687 - val_accuracy: 0.6994\n",
      "Epoch 15/20\n",
      "200/200 [==============================] - 29s 145ms/step - loss: 1.5396 - accuracy: 0.4675 - val_loss: 0.9644 - val_accuracy: 0.6900\n",
      "Epoch 16/20\n",
      "200/200 [==============================] - 31s 157ms/step - loss: 1.4911 - accuracy: 0.4811 - val_loss: 0.8662 - val_accuracy: 0.7375\n",
      "Epoch 17/20\n",
      "200/200 [==============================] - 30s 151ms/step - loss: 1.4763 - accuracy: 0.4909 - val_loss: 0.8714 - val_accuracy: 0.7406\n",
      "Epoch 18/20\n",
      "200/200 [==============================] - 29s 147ms/step - loss: 1.4828 - accuracy: 0.4769 - val_loss: 0.8893 - val_accuracy: 0.7188\n",
      "Epoch 19/20\n",
      "200/200 [==============================] - 30s 147ms/step - loss: 1.4621 - accuracy: 0.4937 - val_loss: 0.8648 - val_accuracy: 0.7200\n",
      "Epoch 20/20\n",
      "200/200 [==============================] - 29s 144ms/step - loss: 1.4434 - accuracy: 0.4901 - val_loss: 0.8779 - val_accuracy: 0.7225\n"
     ]
    }
   ],
   "source": [
    "cnn.fit(imagen_entrenamiento, steps_per_epoch=pasos, epochs=epocas, validation_data=imagen_validacion, validation_steps=pasos_validacion)\n",
    "\n",
    "dir = './modelo/'\n",
    "\n",
    "if not os.path.exists(dir):\n",
    "    os.mkdir(dir)\n",
    "cnn.save('./modelo/modelo.h5')\n",
    "cnn.save_weights('./modelo/pesos.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "worthy-royalty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "200/200 [==============================] - 29s 145ms/step - loss: 1.2796 - accuracy: 0.5472 - val_loss: 0.6987 - val_accuracy: 0.7794\n",
      "Epoch 2/20\n",
      "200/200 [==============================] - 28s 141ms/step - loss: 1.2522 - accuracy: 0.5638 - val_loss: 0.5599 - val_accuracy: 0.8344\n",
      "Epoch 3/20\n",
      "200/200 [==============================] - 29s 143ms/step - loss: 1.2235 - accuracy: 0.5648 - val_loss: 0.5868 - val_accuracy: 0.8331\n",
      "Epoch 4/20\n",
      "200/200 [==============================] - 29s 143ms/step - loss: 1.2573 - accuracy: 0.5588 - val_loss: 0.6087 - val_accuracy: 0.7994\n",
      "Epoch 5/20\n",
      "200/200 [==============================] - 29s 143ms/step - loss: 1.2120 - accuracy: 0.5757 - val_loss: 0.5598 - val_accuracy: 0.8319\n",
      "Epoch 6/20\n",
      "200/200 [==============================] - 28s 142ms/step - loss: 1.2189 - accuracy: 0.5693 - val_loss: 0.5900 - val_accuracy: 0.8263\n",
      "Epoch 7/20\n",
      "200/200 [==============================] - 29s 144ms/step - loss: 1.1941 - accuracy: 0.5820 - val_loss: 0.5322 - val_accuracy: 0.8356\n",
      "Epoch 8/20\n",
      "200/200 [==============================] - 29s 145ms/step - loss: 1.1912 - accuracy: 0.5746 - val_loss: 0.5453 - val_accuracy: 0.8481\n",
      "Epoch 9/20\n",
      "200/200 [==============================] - 29s 145ms/step - loss: 1.1657 - accuracy: 0.5834 - val_loss: 0.6069 - val_accuracy: 0.8031\n",
      "Epoch 10/20\n",
      "200/200 [==============================] - 28s 141ms/step - loss: 1.1858 - accuracy: 0.5777 - val_loss: 0.5921 - val_accuracy: 0.8219\n",
      "Epoch 11/20\n",
      "200/200 [==============================] - 29s 144ms/step - loss: 1.1865 - accuracy: 0.5771 - val_loss: 0.5610 - val_accuracy: 0.8400\n",
      "Epoch 12/20\n",
      "200/200 [==============================] - 28s 142ms/step - loss: 1.1490 - accuracy: 0.5946 - val_loss: 0.4969 - val_accuracy: 0.8544\n",
      "Epoch 13/20\n",
      "200/200 [==============================] - 28s 142ms/step - loss: 1.1361 - accuracy: 0.5947 - val_loss: 0.5472 - val_accuracy: 0.8244\n",
      "Epoch 14/20\n",
      "200/200 [==============================] - 29s 144ms/step - loss: 1.1332 - accuracy: 0.5981 - val_loss: 0.5448 - val_accuracy: 0.8462\n",
      "Epoch 15/20\n",
      "200/200 [==============================] - 29s 144ms/step - loss: 1.1379 - accuracy: 0.6003 - val_loss: 0.5773 - val_accuracy: 0.8144\n",
      "Epoch 16/20\n",
      "200/200 [==============================] - 29s 143ms/step - loss: 1.1244 - accuracy: 0.6003 - val_loss: 0.5814 - val_accuracy: 0.8100\n",
      "Epoch 17/20\n",
      "200/200 [==============================] - 29s 143ms/step - loss: 1.1146 - accuracy: 0.6010 - val_loss: 0.5526 - val_accuracy: 0.8294\n",
      "Epoch 18/20\n",
      "200/200 [==============================] - 29s 145ms/step - loss: 1.1342 - accuracy: 0.5841 - val_loss: 0.5322 - val_accuracy: 0.8413\n",
      "Epoch 19/20\n",
      "200/200 [==============================] - 29s 145ms/step - loss: 1.0927 - accuracy: 0.6052 - val_loss: 0.5117 - val_accuracy: 0.8369\n",
      "Epoch 20/20\n",
      "200/200 [==============================] - 28s 142ms/step - loss: 1.0751 - accuracy: 0.6216 - val_loss: 0.5407 - val_accuracy: 0.8350\n"
     ]
    }
   ],
   "source": [
    "modelo='./modelo/modelo.h5'\n",
    "\n",
    "cnn = load_model(modelo)\n",
    "\n",
    "cnn.fit(imagen_entrenamiento, steps_per_epoch=pasos, epochs=epocas, validation_data=imagen_validacion, validation_steps=pasos_validacion)\n",
    "\n",
    "dir = './modelo/'\n",
    "\n",
    "if not os.path.exists(dir):\n",
    "    os.mkdir(dir)\n",
    "cnn.save('./modelo/modelo.h5')\n",
    "cnn.save_weights('./modelo/pesos.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
