{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "powered-service",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from keras.models import load_model\n",
    "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dropout, Flatten, Dense, Activation\n",
    "from tensorflow.python.keras.layers import Convolution2D, MaxPooling2D\n",
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "from skimage.io import imread\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "considered-mystery",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fifth-catering",
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "latest-handle",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_entrenamiento = './train'\n",
    "data_validacion = './test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "reverse-disease",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parametros red neuronal\n",
    "\n",
    "epocas = 20\n",
    "altura, longitud = 100, 100\n",
    "batch_size = 32\n",
    "pasos = 200\n",
    "pasos_validacion = 50\n",
    "filtrosConv1 = 32\n",
    "filtrosConv2 = 64\n",
    "tamano_filtro1 = (3, 3)\n",
    "tamano_filtro2 = (2, 2)\n",
    "tamano_pool = (2, 2)\n",
    "clases = 29\n",
    "lr = 0.0005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "physical-technician",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M',\n",
       "       'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z',\n",
       "       'del', 'nothing', 'space'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_df = pd.read_csv(r'.\\\\file_target.csv')\n",
    "\n",
    "images_df = images_df.rename(columns={'archivo': 'filenames',\n",
    "                       'target': 'category'})\n",
    "\n",
    "images_df = images_df.sort_values('category')\n",
    "\n",
    "images_df['category'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "chubby-combination",
   "metadata": {},
   "outputs": [],
   "source": [
    "entrenamiento, validacion = train_test_split(images_df, test_size = 0.19)\n",
    "\n",
    "entrenamiento = entrenamiento.reset_index(drop=True)\n",
    "\n",
    "entrenamiento = entrenamiento.sort_values('category')\n",
    "\n",
    "validacion = validacion.reset_index(drop=True)\n",
    "\n",
    "validacion = validacion.sort_values('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "durable-criterion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7290 validated image filenames belonging to 29 classes.\n",
      "Found 1710 validated image filenames belonging to 29 classes.\n"
     ]
    }
   ],
   "source": [
    "#Pre-procesamiento de las im√°genes\n",
    "#Primero creamos un generador que dice como vamos a preprocesar la info\n",
    "\n",
    "entrenamiento_datagen = ImageDataGenerator(rescale = 1.0/255.0,\n",
    "                                          shear_range = 0.3,\n",
    "                                          zoom_range = 0.3,\n",
    "                                          horizontal_flip = True)\n",
    "\n",
    "validacion_datagen = ImageDataGenerator(rescale = 1.0/255.0)\n",
    "\n",
    "imagen_entrenamiento = entrenamiento_datagen.flow_from_dataframe(entrenamiento,\n",
    "                                                                 data_entrenamiento,\n",
    "                                                                 target_size=(altura, longitud),\n",
    "                                                                 x_col='filenames',\n",
    "                                                                y_col='category',\n",
    "                                                                batch_size=batch_size,\n",
    "                                                                class_mode='categorical')\n",
    "\n",
    "imagen_validacion = validacion_datagen.flow_from_dataframe(validacion,\n",
    "                                                           data_entrenamiento,\n",
    "                                                          target_size=(altura, longitud),\n",
    "                                                           x_col='filenames',\n",
    "                                                            y_col='category',\n",
    "                                                          batch_size=batch_size,\n",
    "                                                          class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "flush-italian",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn=Sequential()\n",
    "\n",
    "cnn.add(Convolution2D(filtrosConv1, tamano_filtro1, padding='same', input_shape=(altura, longitud, 3), activation='relu'))\n",
    "\n",
    "cnn.add(MaxPooling2D(pool_size=tamano_pool))\n",
    "\n",
    "cnn.add(Convolution2D(filtrosConv2, tamano_filtro2, padding='same', activation='relu'))\n",
    "\n",
    "cnn.add(MaxPooling2D(pool_size=tamano_pool))\n",
    "\n",
    "cnn.add(Flatten())\n",
    "\n",
    "cnn.add(Dense(256, activation='relu'))\n",
    "\n",
    "cnn.add(Dropout(0.5))\n",
    "\n",
    "cnn.add(Dense(clases, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "consistent-lottery",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(loss='categorical_crossentropy', optimizer=optimizers.Adam(lr=lr), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "statewide-career",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "200/200 [==============================] - 27s 133ms/step - loss: 1.6955 - accuracy: 0.4206 - val_loss: 1.0881 - val_accuracy: 0.6556\n",
      "Epoch 2/20\n",
      "200/200 [==============================] - 28s 141ms/step - loss: 1.6705 - accuracy: 0.4299 - val_loss: 1.0871 - val_accuracy: 0.6712\n",
      "Epoch 3/20\n",
      "200/200 [==============================] - 31s 154ms/step - loss: 1.6640 - accuracy: 0.4285 - val_loss: 1.0807 - val_accuracy: 0.6500\n",
      "Epoch 4/20\n",
      "200/200 [==============================] - 30s 150ms/step - loss: 1.6618 - accuracy: 0.4285 - val_loss: 1.0418 - val_accuracy: 0.6837\n",
      "Epoch 5/20\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 1.6466 - accuracy: 0.4392 - val_loss: 1.1705 - val_accuracy: 0.6075\n",
      "Epoch 6/20\n",
      "200/200 [==============================] - 29s 146ms/step - loss: 1.6333 - accuracy: 0.4409 - val_loss: 0.9776 - val_accuracy: 0.7138\n",
      "Epoch 7/20\n",
      "200/200 [==============================] - 29s 144ms/step - loss: 1.6277 - accuracy: 0.4464 - val_loss: 1.0722 - val_accuracy: 0.6756\n",
      "Epoch 8/20\n",
      "200/200 [==============================] - 29s 144ms/step - loss: 1.6089 - accuracy: 0.4421 - val_loss: 0.9946 - val_accuracy: 0.6950\n",
      "Epoch 9/20\n",
      "200/200 [==============================] - 30s 150ms/step - loss: 1.5968 - accuracy: 0.4525 - val_loss: 1.0326 - val_accuracy: 0.6963\n",
      "Epoch 10/20\n",
      "200/200 [==============================] - 30s 149ms/step - loss: 1.5744 - accuracy: 0.4551 - val_loss: 1.0188 - val_accuracy: 0.6787\n",
      "Epoch 11/20\n",
      "200/200 [==============================] - 29s 146ms/step - loss: 1.5576 - accuracy: 0.4661 - val_loss: 0.9399 - val_accuracy: 0.7094\n",
      "Epoch 12/20\n",
      "200/200 [==============================] - 31s 153ms/step - loss: 1.5270 - accuracy: 0.4693 - val_loss: 0.9508 - val_accuracy: 0.7006\n",
      "Epoch 13/20\n",
      "200/200 [==============================] - 31s 153ms/step - loss: 1.5270 - accuracy: 0.4673 - val_loss: 0.9199 - val_accuracy: 0.7131\n",
      "Epoch 14/20\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 1.5286 - accuracy: 0.4673 - val_loss: 0.9687 - val_accuracy: 0.6994\n",
      "Epoch 15/20\n",
      "200/200 [==============================] - 29s 145ms/step - loss: 1.5396 - accuracy: 0.4675 - val_loss: 0.9644 - val_accuracy: 0.6900\n",
      "Epoch 16/20\n",
      "200/200 [==============================] - 31s 157ms/step - loss: 1.4911 - accuracy: 0.4811 - val_loss: 0.8662 - val_accuracy: 0.7375\n",
      "Epoch 17/20\n",
      "200/200 [==============================] - 30s 151ms/step - loss: 1.4763 - accuracy: 0.4909 - val_loss: 0.8714 - val_accuracy: 0.7406\n",
      "Epoch 18/20\n",
      "200/200 [==============================] - 29s 147ms/step - loss: 1.4828 - accuracy: 0.4769 - val_loss: 0.8893 - val_accuracy: 0.7188\n",
      "Epoch 19/20\n",
      "200/200 [==============================] - 30s 147ms/step - loss: 1.4621 - accuracy: 0.4937 - val_loss: 0.8648 - val_accuracy: 0.7200\n",
      "Epoch 20/20\n",
      "200/200 [==============================] - 29s 144ms/step - loss: 1.4434 - accuracy: 0.4901 - val_loss: 0.8779 - val_accuracy: 0.7225\n"
     ]
    }
   ],
   "source": [
    "cnn.fit(imagen_entrenamiento, steps_per_epoch=pasos, epochs=epocas, validation_data=imagen_validacion, validation_steps=pasos_validacion)\n",
    "\n",
    "dir = './modelo/'\n",
    "\n",
    "if not os.path.exists(dir):\n",
    "    os.mkdir(dir)\n",
    "cnn.save('./modelo/modelo.h5')\n",
    "cnn.save_weights('./modelo/pesos.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "clean-royal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "200/200 [==============================] - 27s 133ms/step - loss: 1.4023 - accuracy: 0.5095 - val_loss: 0.8223 - val_accuracy: 0.7444\n",
      "Epoch 2/20\n",
      "200/200 [==============================] - 28s 141ms/step - loss: 1.4237 - accuracy: 0.4997 - val_loss: 0.8185 - val_accuracy: 0.7594\n",
      "Epoch 3/20\n",
      "200/200 [==============================] - 30s 149ms/step - loss: 1.3914 - accuracy: 0.5239 - val_loss: 0.8289 - val_accuracy: 0.7544\n",
      "Epoch 4/20\n",
      "200/200 [==============================] - 30s 149ms/step - loss: 1.3875 - accuracy: 0.5158 - val_loss: 0.8613 - val_accuracy: 0.7362\n",
      "Epoch 5/20\n",
      "200/200 [==============================] - 29s 147ms/step - loss: 1.3691 - accuracy: 0.5225 - val_loss: 0.8183 - val_accuracy: 0.7625\n",
      "Epoch 6/20\n",
      "200/200 [==============================] - 30s 150ms/step - loss: 1.3836 - accuracy: 0.5127 - val_loss: 0.7837 - val_accuracy: 0.7638\n",
      "Epoch 7/20\n",
      "200/200 [==============================] - 29s 147ms/step - loss: 1.3797 - accuracy: 0.5147 - val_loss: 0.8957 - val_accuracy: 0.7031\n",
      "Epoch 8/20\n",
      "200/200 [==============================] - 29s 144ms/step - loss: 1.3478 - accuracy: 0.5205 - val_loss: 0.7829 - val_accuracy: 0.7606\n",
      "Epoch 9/20\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 1.3357 - accuracy: 0.5241 - val_loss: 0.7676 - val_accuracy: 0.7606\n",
      "Epoch 10/20\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 1.3310 - accuracy: 0.5336 - val_loss: 0.7323 - val_accuracy: 0.7781\n",
      "Epoch 11/20\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 1.3158 - accuracy: 0.5321 - val_loss: 0.7531 - val_accuracy: 0.7706\n",
      "Epoch 12/20\n",
      "200/200 [==============================] - 28s 141ms/step - loss: 1.3261 - accuracy: 0.5391 - val_loss: 0.7501 - val_accuracy: 0.7619\n",
      "Epoch 13/20\n",
      "200/200 [==============================] - 28s 142ms/step - loss: 1.3057 - accuracy: 0.5437 - val_loss: 0.7525 - val_accuracy: 0.7613\n",
      "Epoch 14/20\n",
      "200/200 [==============================] - 28s 141ms/step - loss: 1.3207 - accuracy: 0.5350 - val_loss: 0.7279 - val_accuracy: 0.7656\n",
      "Epoch 15/20\n",
      "200/200 [==============================] - 28s 142ms/step - loss: 1.2784 - accuracy: 0.5506 - val_loss: 0.7295 - val_accuracy: 0.7750\n",
      "Epoch 16/20\n",
      "200/200 [==============================] - 30s 149ms/step - loss: 1.2826 - accuracy: 0.5405 - val_loss: 0.7128 - val_accuracy: 0.7738\n",
      "Epoch 17/20\n",
      "200/200 [==============================] - 30s 150ms/step - loss: 1.2599 - accuracy: 0.5580 - val_loss: 0.6968 - val_accuracy: 0.7650\n",
      "Epoch 18/20\n",
      "200/200 [==============================] - 31s 155ms/step - loss: 1.2370 - accuracy: 0.5568 - val_loss: 0.7786 - val_accuracy: 0.7369\n",
      "Epoch 19/20\n",
      "200/200 [==============================] - 30s 151ms/step - loss: 1.2266 - accuracy: 0.5708 - val_loss: 0.6880 - val_accuracy: 0.7763\n",
      "Epoch 20/20\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 1.2517 - accuracy: 0.5502 - val_loss: 0.6646 - val_accuracy: 0.7950\n"
     ]
    }
   ],
   "source": [
    "modelo='./modelo/modelo.h5'\n",
    "\n",
    "cnn = load_model(modelo)\n",
    "\n",
    "cnn.fit(imagen_entrenamiento, steps_per_epoch=pasos, epochs=epocas, validation_data=imagen_validacion, validation_steps=pasos_validacion)\n",
    "\n",
    "dir = './modelo/'\n",
    "\n",
    "if not os.path.exists(dir):\n",
    "    os.mkdir(dir)\n",
    "cnn.save('./modelo/modelo.h5')\n",
    "cnn.save_weights('./modelo/pesos.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "portable-status",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
